
# Heart Disease Prediction

Predict the likelihood of a heart disease by using Machine Learning with an intuitive approach.

## Description


Heart disease, also referred to as cardiovascular disease, is a leading cause of death worldwide, responsible for millions of deaths annually. It encompasses a range of conditions affecting the heart, including coronary artery disease, arrhythmias, and heart failure. Early diagnosis and timely intervention are crucial in mitigating its impact, which is where technology, including machine learning, plays a vital role.
## 

![App Screenshot](https://cdn.pixabay.com/photo/2024/01/05/22/02/ai-generated-8490212_1280.jpg)



## Project Aim
By leveraging machine learning to predict the likelihood of heart disease based on clinical and lifestyle factors, we can help healthcare providers take proactive measures and save lives. This project aims to bridge the gap between early detection and timely treatment through data-driven insights.
## Key Features

- Exploratory Data Analysis (EDA) to uncover insights.
- Data preprocessing: handling missing values, scaling, and encoding.
- Model building and evaluation using KNN, Random Forest, and Logistic Regression.
- Deployed on [GitHub](https://github.com/karanBx/HeartDiseasePrediction.git) 


## Tech Stack

Programming Language:   Python

Data Science Libraries: NumPy, Pandas, Scikit-learn

Visualization Libraries: Matplotlib, Seaborn, Plotly

Environment: Google Colab/Jupyter Notebook

![Python](https://img.shields.io/badge/Python-3.8-blue)
![Scikit-learn](https://img.shields.io/badge/Scikit--learn-0.24-orange)
![Pandas](https://img.shields.io/badge/Pandas-1.3-yellow)
![Matplotlib](https://img.shields.io/badge/Matplotlib-3.4-green) 











## Installation
1. Clone this repository:
   ```
   git clone https://github.com/username/heart-disease-prediction.git
   ```
2. Navigate to the project directory:
   ```
   cd heart-disease-prediction
   ```
3. Install the required dependencies:
   ```
   pip install -r requirements.txt
   ```
    
## Workflow
1. Data Ingestion
2. Data Transformation
3. Model training with various algorithms.
4. Model evaluation and selection.
5. Deployment and usage.

## Dataset
- Source: [UCI Heart Disease Dataset](https://archive.ics.uci.edu/ml/datasets/heart+Disease)
- Rows: 303
- Columns: 14
- Target Variable: `target` (0 = No Disease, 1 = Disease)


## Understanding Dataset

Age: Age in years

Sex: Sex (1 = male, 0 = female)

Chest Pain Type (cp):-
Value 1: Typical angina
Value 2: Atypical angina
Value 3: Non-anginal pain
Value 4: Asymptomatic

Resting Blood Pressure (trestbps): Resting blood pressure measured in mmHg on admission to the hospital

Serum Cholesterol (chol): Serum cholesterol measured in mg/dl

Fasting Blood Sugar (fbs): Fasting blood sugar >120 mg/dl (1 = true, 0 = false)

Resting Electrocardiographic Results (restecg):-
Value 0: Normal
Value 1: Having ST-T wave abnormality (T wave inversions and/or ST elevation or depression of > 0.05mV)
Value 2: Showing probable or definite left ventricular hypertrophy by Estes' criteria

Maximum Heart Rate Achieved (thalach): Maximum heart rate achieved

Exercise-Induced Angina (exang): Exercise-induced angina (1 = yes, 0 = no)

ST Depression (oldpeak): ST depression induced by exercise relative to rest

Slope of Peak Exercise ST Segment (slope):-
Value 1: Upsloping
Value 2: Flat
Value 3: Downsloping
Number of Major Vessels Colored by Fluoroscopy (ca): Number of major vessels (0-3) colored by fluoroscopy

Thalassemia (thal):-
Value 3: Normal
Value 6: Fixed defect
Value 7: Reversible defect

Heart Disease Diagnosis (HeartDisease):-
Value 0: <50% diameter narrowing
Value 1: >50% diameter narrowing
## CONCLUSION


From the results of dataset analysis and implementation of machine learning models in the previous section, it can be concluded as follows:

Logistic regression and KNN were comparatively the best machine-learning models in this notebook. This is because this model fits well with train and test data.

The prediction results on test data, dummy data, and the complete machine learning pipeline have been successfully exported for other purposes. In addition, data exploration has also been successfully carried out using the ydata-profiling, seaborn, and matplotlib libraries.

Several improvements can be implemented in the following research/notebook. Another example is performing advanced hyperparameter tuning experiments to obtain higher accuracy (~90%).
## References

-An Introduction to Logistic Regression in Python by Simplilearn:
https://www.simplilearn.com/tutorials/machine-learning-tutorial/logistic-regression-in-python

-What Is K-Nearest Neighbor? An ML Algorithm to Classify Data by Amal Joby:
https://learn.g2.com/k-nearest-neighbor

-Decision Tree Classification Algorithm by Javatpoint
https://www.javatpoint.com/machine-learning-decision-tree-classification-algorithm

-Decision Tree vs. Random Forest â€“ Which Algorithm Should you Use? by Abhishek Sharma
https://www.analyticsvidhya.com/blog/2020/05/decision-tree-vs-random-forest-algorithm/

-Understanding Random Forest by Tony Yiu
https://towardsdatascience.com/understanding-random-forest-58381e0602d2
## Contributions

Contributions are welcome! Please open an issue or submit a pull request for any improvements.

